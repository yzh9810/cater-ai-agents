{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m     batch_options \u001b[38;5;241m=\u001b[39m options[start:end]\n\u001b[0;32m     74\u001b[0m     tasks\u001b[38;5;241m.\u001b[39mappend(async_search(prompt, user_input, batch_options))\n\u001b[1;32m---> 76\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     79\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\yuezo\\anaconda\\lib\\asyncio\\runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/yuezo/OneDrive/桌面/project/cater-ai-agents/models/LCEL_engine/')\n",
    "sys.path.append('C:/Users/yuezo/OneDrive/桌面/project/cater-ai-agents/models/Menu_Retriever/')\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from menu_retriever import *\n",
    "import time\n",
    "\n",
    "import asyncio\n",
    "import configparser\n",
    "import math\n",
    "import json\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__e33af7b422394942b1ca565215fd1b92\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0, model_kwargs={\"response_format\": { \"type\": \"json_object\"}})\n",
    "async def async_search(prompt, user_input, options):\n",
    "    prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "    options = str(options)\n",
    "    # print(\"input = \", user_input)\n",
    "    # print(\"options = \", options)\n",
    "    args = {\n",
    "        \"options\": options,\n",
    "        \"input\": user_input\n",
    "    }\n",
    "\n",
    "    output_parser = StrOutputParser()\n",
    "    chain = prompt_template | model | output_parser\n",
    "\n",
    "    response = await chain.ainvoke(args)\n",
    "    return response\n",
    "\n",
    "def sync_search(prompt, user_input, options):\n",
    "    prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "    options = str(options)\n",
    "    # print(\"input = \", user_input)\n",
    "    # print(\"options = \", options)\n",
    "    args = {\n",
    "        \"options\": options,\n",
    "        \"input\": user_input\n",
    "    }\n",
    "\n",
    "    output_parser = StrOutputParser()\n",
    "    chain = prompt_template | model | output_parser\n",
    "\n",
    "    response = chain.invoke(args)\n",
    "    return response\n",
    "\n",
    "model = ChatOpenAI(model='gpt-3.5-turbo', temperature=0,  model_kwargs={\"response_format\": { \"type\": \"json_object\"}})\n",
    "menu_retriever = Menu_Loading(\"C:/Users/yuezo/OneDrive/桌面/project/cater-ai-agents/scripts/example.cfg\")\n",
    "with open(\"C:/Users/yuezo/OneDrive/桌面/project/cater-ai-agents/models/prompts/seach_engine_prompts/similarity_search_with_nonfound.txt\") as file:\n",
    "    prompt = file.read()\n",
    "\n",
    "items_from_menu = list(menu_retriever.get_items().keys())\n",
    "\n",
    "options = [{\"name\": item, \"description\": menu_retriever.get_items()[item][\"Description\"]} for item in items_from_menu]\n",
    "user_input = \"boba milk tea\"\n",
    "\n",
    "num_each_batch = 5\n",
    "num_options = len(options)\n",
    "num_batches = math.ceil(num_options / num_each_batch)\n",
    "\n",
    "selected_options = {}\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "tasks = []\n",
    "for i in range(num_batches):\n",
    "    start = i * num_each_batch\n",
    "    end = min((i + 1) * num_each_batch, num_options)\n",
    "    batch_options = options[start:end]\n",
    "    tasks.append(async_search(prompt, user_input, batch_options))\n",
    "\n",
    "result = asyncio.run(asyncio.gather(*tasks))\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"elapsed_time = \", elapsed_time, \"result = \", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def run_divide_and_conquer_async():\n",
    "    await asyncio.sleep(1)  # 代替实际的异步操作\n",
    "    return \"done\"\n",
    "\n",
    "# 获取当前事件循环\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "# 在现有的事件循环中运行协程\n",
    "result = await loop.create_task(run_divide_and_conquer_async())\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
